{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append(\"/c/users/.dgl/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset  = pd.read_csv('./ydata-ymusic-rating-study-v1_0-train.txt', header = None, sep = '\\t',  encoding='latin-1', error_bad_lines=False ) \n",
    "testset  = pd.read_csv('./ydata-ymusic-rating-study-v1_0-test.txt', header = None, sep = '\\t',  encoding='latin-1', error_bad_lines=False ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.rename({0 : 'userId', 1 : 'itemId', 2 : 'rating'}, axis = 1, inplace = True)\n",
    "testset.rename({0 : 'userId', 1 : 'itemId', 2 : 'rating'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTensor(list, bool): \n",
    "\n",
    "    if bool:\n",
    "        list = torch.LongTensor(list.astype('category')\n",
    "                                .cat.codes.values) # Konvertiere zu category damit cat.codes ausgeführt werden kann.\n",
    "    else:\n",
    "        list = torch.LongTensor(list.values)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'item': 1000, 'user': 15400},\n",
      "      num_edges={('item', 'rated-by', 'user'): 311704, ('user', 'rated', 'item'): 311704},\n",
      "      metagraph=[('item', 'user', 'rated-by'), ('user', 'item', 'rated')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\envs\\graphlearning\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:189.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "userId = torch.LongTensor(trainset['userId'].astype('category').cat.codes.values) \n",
    "itemId = torch.LongTensor(trainset['itemId'].astype('category').cat.codes.values) \n",
    "\n",
    "userIdTest = torch.LongTensor(testset['userId'].astype('category').cat.codes.values) \n",
    "itemIdTest = torch.LongTensor(testset['itemId'].astype('category').cat.codes.values) \n",
    "\n",
    "\n",
    "graph = dgl.heterograph({\n",
    "    ('user', 'rated', 'item'): (userId, itemId),\n",
    "    ('item', 'rated-by', 'user'): (itemId, userId)\n",
    "})\n",
    " \n",
    "print(graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yah = buildTensor(trainset['rating'], False)\n",
    "yahTest = buildTensor(testset['rating'], False) \n",
    "graph.edges['rated'].data['rating'] = yah\n",
    "graph.edges['rated-by'].data['rating'] = yah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorTrainset = TensorDataset(userId, itemId, yah)\n",
    "tensorTestset = TensorDataset(userIdTest, itemIdTest, yahTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchSampler(object):\n",
    "    \n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def sample(self, batch):\n",
    "        users, items, ratings = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        ratings = torch.stack(ratings)\n",
    "        \n",
    "        pair_graph = dgl.heterograph(\n",
    "            {('user', 'rated', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "        pair_graph = dgl.compact_graphs(pair_graph) \n",
    "        pair_graph.edata['rating'] = ratings \n",
    "        \n",
    "        seeds = {'user': pair_graph.nodes['user'].data[dgl.NID], \n",
    "                 'item': pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        blocks = self.construct_blocks(seeds, (users, items)) \n",
    "        \n",
    "        for feature_name in self.graph.nodes['user'].data.keys():\n",
    "            blocks[0].srcnodes['user'].data[feature_name] = \\\n",
    "                self.graph.nodes['user'].data[feature_name][blocks[0].srcnodes['user'].data[dgl.NID]] \n",
    "            \n",
    "        for feature_name in self.graph.nodes['item'].data.keys():\n",
    "            blocks[0].srcnodes['item'].data[feature_name] = \\\n",
    "                self.graph.nodes['item'].data[feature_name][blocks[0].srcnodes['item'].data[dgl.NID]]\n",
    "        \n",
    "\n",
    "        return pair_graph, blocks \n",
    "    \n",
    "\n",
    "    def construct_blocks(self, seeds, user_item_pairs_to_remove):\n",
    "        blocks = []\n",
    "        users, items = user_item_pairs_to_remove\n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "            sampled_graph = dgl.in_subgraph(self.graph, seeds) \n",
    "\n",
    "            sampled_eids = sampled_graph.edges['rated'].data[dgl.EID]\n",
    "            sampled_eids_rev = sampled_graph.edges['rated-by'].data[dgl.EID]\n",
    "            \n",
    "\n",
    "            _, _, edges_to_remove = sampled_graph.edge_ids(users, items, etype='rated', return_uv=True)  \n",
    "            _, _, edges_to_remove_rev = sampled_graph.edge_ids(items, users, etype='rated-by', return_uv=True)\n",
    "            \n",
    "            sampled_with_edges_removed = sampled_graph\n",
    "            if len(edges_to_remove) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove, 'rated')\n",
    "                sampled_eids = sampled_eids[sampled_with_edges_removed.edges['rated'].data[dgl.EID]]\n",
    "                \n",
    "            if len(edges_to_remove_rev) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove_rev, 'rated-by')\n",
    "                sampled_eids_rev = sampled_eids_rev[sampled_with_edges_removed.edges['rated-by'].data[dgl.EID]]\n",
    "            \n",
    "\n",
    "            block = dgl.to_block(sampled_with_edges_removed, seeds)\n",
    "            blocks.insert(0, block)\n",
    "            seeds = {'user': block.srcnodes['user'].data[dgl.NID],\n",
    "                     'item': block.srcnodes['item'].data[dgl.NID]}\n",
    "            \n",
    "\n",
    "            block.edges['rated'].data['rating'] = \\\n",
    "                self.graph.edges['rated'].data['rating'][sampled_eids]\n",
    "            block.edges['rated-by'].data['rating'] = \\\n",
    "                self.graph.edges['rated-by'].data['rating'][sampled_eids_rev]\n",
    "            \n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class GCMCConv(nn.Module): \n",
    "    \n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W_r = nn.Parameter(torch.randn(num_ratings + 1, hidden_dims, hidden_dims)) \n",
    "        self.W_i = nn.Linear(hidden_dims * 2, hidden_dims) \n",
    "        \n",
    "    def compute_message(self, W, edges): \n",
    "        W_r = W[edges.data['rating']]\n",
    "        h = edges.src['h'] \n",
    "        m = (W_r @ h.unsqueeze(-1)).squeeze(2) \n",
    "        return m\n",
    "\n",
    "    def forward(self, graph, node_features):\n",
    "        with graph.local_scope():\n",
    "            src_features, dst_features = node_features\n",
    "            \n",
    "            graph.srcdata['h'] = src_features \n",
    "            graph.dstdata['h'] = dst_features \n",
    "            \n",
    "            graph.apply_edges(lambda edges: {'m': self.compute_message(self.W_r, edges)})\n",
    "            \n",
    "            graph.update_all(fn.copy_e('m', 'm'), fn.mean('m', 'h_neigh'))  \n",
    "            \n",
    "            result = F.relu(self.W_i(torch.cat([graph.dstdata['h'], graph.dstdata['h_neigh']], 1))) \n",
    "            return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.heteroconv = dglnn.HeteroGraphConv(\n",
    "            {'rated': GCMCConv(hidden_dims, num_ratings), 'rated-by': GCMCConv(hidden_dims, num_ratings)},\n",
    "            aggregate='sum')\n",
    "                \n",
    "    def forward(self, block, input_user_features, input_item_features):\n",
    "        with block.local_scope():\n",
    "\n",
    "            h_user = input_user_features \n",
    "            h_item = input_item_features\n",
    "            \n",
    "            src_features = {'user': h_user, 'item': h_item} \n",
    "            dst_features = {'user': h_user[:block.number_of_dst_nodes('user')],\n",
    "                            'item': h_item[:block.number_of_dst_nodes('item')]} \n",
    "            \n",
    "            result = self.heteroconv(block, (src_features, dst_features))\n",
    "            return result['user'], result['item']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heteroconv = dglnn.HeteroGraphConv(\n",
    "            {'rated': GCMCConv(hidden_dims, num_ratings), 'rated-by': GCMCConv(hidden_dims, num_ratings)},\n",
    "            aggregate='sum')\n",
    "                \n",
    "    def forward(self, block, input_user_features, input_item_features):\n",
    "        with block.local_scope():\n",
    "            h_user = input_user_features \n",
    "            h_item = input_item_features\n",
    "            \n",
    "            src_features = {'user': h_user, 'item': h_item} \n",
    "            dst_features = {'user': h_user[:block.number_of_dst_nodes('user')],\n",
    "                            'item': h_item[:block.number_of_dst_nodes('item')]} \n",
    "            \n",
    "            result = self.heteroconv(block, (src_features, dst_features))\n",
    "            return result['user'], result['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCRating(nn.Module):\n",
    "    def __init__(self, num_users, num_items, hidden_dims, num_ratings, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, hidden_dims)  \n",
    "        self.item_embeddings = nn.Embedding(num_items, hidden_dims)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            GCMCLayer(hidden_dims, num_ratings) for _ in range(num_layers)]) \n",
    "        \n",
    "        self.W_u = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.W_v = nn.Linear(hidden_dims, hidden_dims)\n",
    "        \n",
    "    def forward(self, blocks):\n",
    "        user_embeddings = self.user_embeddings(blocks[0].srcnodes['user'].data[dgl.NID])\n",
    "        item_embeddings = self.item_embeddings(blocks[0].srcnodes['item'].data[dgl.NID])\n",
    "        \n",
    "        for block, layer in zip(blocks, self.layers):\n",
    "            user_embeddings, item_embeddings = layer(block, user_embeddings, item_embeddings) \n",
    "        \n",
    "        z_u = self.W_u(user_embeddings) \n",
    "        z_v = self.W_v(item_embeddings)\n",
    "        \n",
    "        return z_u, z_v\n",
    "    \n",
    "    def compute_score(self, pair_graph, z_u, z_v):\n",
    "        with pair_graph.local_scope():\n",
    "            pair_graph.nodes['user'].data['h'] = z_u \n",
    "            pair_graph.nodes['item'].data['h'] = z_v\n",
    "            \n",
    "            pair_graph.apply_edges(fn.u_dot_v('h', 'h', 'r')) \n",
    "            \n",
    "            return pair_graph.edata['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def trainingLoop(NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, HIDDEN_DIMS, NUM_RATINGS, printing = True):\n",
    "    sampler = MinibatchSampler(graph, NUM_LAYERS) \n",
    "    \n",
    "    train_dataloader = DataLoader(tensorTrainset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=True)\n",
    "    test_dataloader = DataLoader(tensorTestset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=False)\n",
    "        \n",
    "    model = GCMCRating(graph.number_of_nodes('user'), graph.number_of_nodes('item'), HIDDEN_DIMS, NUM_RATINGS, NUM_LAYERS) \n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "    \n",
    "    rmse = []\n",
    "    \n",
    "    for i in range(NUM_EPOCHS):\n",
    "        \n",
    "        model.train() \n",
    "        \n",
    "        with tqdm.tqdm(train_dataloader) as t: \n",
    "            for pair_graph, blocks in t:\n",
    "                user_emb, item_emb = model(blocks)\n",
    "                prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "                loss = ((prediction - pair_graph.edata['rating']) ** 2).mean()\n",
    "                opt.zero_grad() \n",
    "                loss.backward() \n",
    "                opt.step() \n",
    "                \n",
    "        model.eval() \n",
    "        \n",
    "        with tqdm.tqdm(test_dataloader) as t: \n",
    "            with torch.no_grad():\n",
    "                predictions = []\n",
    "                ratings = []\n",
    "                for pair_graph, blocks in t:\n",
    "\n",
    "                    user_emb, item_emb = model(blocks) \n",
    "\n",
    "                    prediction = model.compute_score(pair_graph, user_emb, item_emb) \n",
    "                    predictions.append(prediction) \n",
    "                    ratings.append(pair_graph.edata['rating']) \n",
    "                    \n",
    "                predictions = torch.cat(predictions, 0)\n",
    "                ratings = torch.cat(ratings, 0)\n",
    "        \n",
    "        if printing:\n",
    "            print('RMSE:', mean_squared_error(predictions, ratings, squared=True).item(),'- after',i+1,'Epoch:')\n",
    "        \n",
    "        rmse.append(mean_squared_error(predictions, ratings, squared=True).item())\n",
    "    \n",
    "    if printing:\n",
    "        print('\\n\\nEvaluation for the following hyper parameters: \\n',\n",
    "              'NUM_LAYERS','=', NUM_LAYERS, '\\n',\n",
    "              'BATCH_SIZE','=', BATCH_SIZE, '\\n',\n",
    "              'NUM_EPOCHS','=', NUM_EPOCHS, '\\n',\n",
    "              'HIDDEN_DIMS','=', HIDDEN_DIMS, '\\n') \n",
    "        print('Endgültiger RMSE:', mean_squared_error(predictions, ratings, squared=True).item())\n",
    "    \n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/312 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 232905 is out of bounds for dimension 0 with size 232290",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24172/4097024616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mNUM_RATINGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainingLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHIDDEN_DIMS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_RATINGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24172/2176161288.py\u001b[0m in \u001b[0;36mtrainingLoop\u001b[1;34m(NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, HIDDEN_DIMS, NUM_RATINGS, printing)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mpair_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0muser_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_emb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphlearning\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphlearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphlearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphlearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24172/2247566648.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     20\u001b[0m         seeds = {'user': pair_graph.nodes['user'].data[dgl.NID], \n\u001b[0;32m     21\u001b[0m                  'item': pair_graph.nodes['item'].data[dgl.NID]}\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24172/2247566648.py\u001b[0m in \u001b[0;36mconstruct_blocks\u001b[1;34m(self, seeds, user_item_pairs_to_remove)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 sampled_with_edges_removed = dgl.remove_edges(\n\u001b[0;32m     53\u001b[0m                     sampled_with_edges_removed, edges_to_remove, 'rated')\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[0msampled_eids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampled_eids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampled_with_edges_removed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rated'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_to_remove_rev\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 232905 is out of bounds for dimension 0 with size 232290"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS = 1 \n",
    "BATCH_SIZE = 1000 \n",
    "NUM_EPOCHS = 15 \n",
    "HIDDEN_DIMS = 8 \n",
    "NUM_RATINGS = len(set(trainset['rating'])) \n",
    "\n",
    "rmse = trainingLoop(NUM_LAYERS, BATCH_SIZE, NUM_EPOCHS, HIDDEN_DIMS, NUM_RATINGS) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphlearning",
   "language": "python",
   "name": "graphlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
