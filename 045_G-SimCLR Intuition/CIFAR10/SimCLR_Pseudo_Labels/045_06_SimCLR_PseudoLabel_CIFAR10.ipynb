{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "045_06_SimCLR_PseudoLabel_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3-v4TaIjXOW"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2eKarqEa6Jq",
        "outputId": "c087f94c-4bc2-420e-b96c-2296c3c242a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TensorFlow Imports\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHIQyrTzbDdp",
        "outputId": "6fc01e1c-9e00-4095-95dd-6cfe05fc4480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Which GPU?\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct  1 14:27:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9psdSeZuVY",
        "outputId": "3ab4ab37-b499-4299-f17d-c751544e1e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-01 14:27:40--  https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6064 (5.9K) [text/plain]\n",
            "Saving to: ‘resnet_cifar10.py’\n",
            "\n",
            "resnet_cifar10.py   100%[===================>]   5.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-01 14:27:40 (37.4 MB/s) - ‘resnet_cifar10.py’ saved [6064/6064]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5VbrcNoj6C7",
        "outputId": "08a146bf-6beb-4ec8-dc8d-c3d059233478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install -q wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7MB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 32.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 31.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXT3bKVbjlo",
        "outputId": "472cd7d7-f026-44e9-dbfa-cc5c98431910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import resnet_cifar10\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "# Authorize wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNS3zVGZuVi"
      },
      "source": [
        "# ResNetCIFAR10\n",
        "n = 4\n",
        "depth =  n * 9 + 2\n",
        "n_blocks = ((depth - 2) // 9) - 1\n",
        "\n",
        "# The input tensor\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# The Stem Convolution Group\n",
        "x = resnet_cifar10.stem(inputs)\n",
        "   \n",
        "# The learner\n",
        "outputs = resnet_cifar10.learner(x, n_blocks)\n",
        "\n",
        "# Instantiate the Model\n",
        "resnet_headless_model = Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20oIWhxZuVl",
        "outputId": "e24bfefc-d426-42ac-99de-a022a2257d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet_headless_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 32, 32, 16)   64          conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_164 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 16)   272         re_lu_164[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 32, 32, 16)   64          conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_165 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_165[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 32, 32, 16)   64          conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_166 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_166[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_164[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 32, 32, 64)   256         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 32, 32, 64)   0           conv2d_167[0][0]                 \n",
            "                                                                 batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_167 (ReLU)                (None, 32, 32, 64)   0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_167[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 32, 32, 16)   64          conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_168 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_168[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 32, 32, 16)   64          conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_169 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_169[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 32, 32, 64)   256         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 32, 32, 64)   0           batch_normalization_170[0][0]    \n",
            "                                                                 re_lu_167[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_170 (ReLU)                (None, 32, 32, 64)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_170[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 32, 32, 16)   64          conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_171 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_171[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 32, 32, 16)   64          conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_172 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_172[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 32, 32, 64)   256         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 32, 32, 64)   0           batch_normalization_173[0][0]    \n",
            "                                                                 re_lu_170[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_173 (ReLU)                (None, 32, 32, 64)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_173[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 32, 32, 16)   64          conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_174 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_174[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 32, 32, 16)   64          conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_175 (ReLU)                (None, 32, 32, 16)   0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_175[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 32, 32, 64)   256         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 64)   0           batch_normalization_176[0][0]    \n",
            "                                                                 re_lu_173[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_176 (ReLU)                (None, 32, 32, 64)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 32, 32, 64)   4160        re_lu_176[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 32, 32, 64)   256         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_177 (ReLU)                (None, 32, 32, 64)   0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_177[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 16, 16, 64)   256         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_178 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_178[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_176[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 16, 16, 128)  512         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 16, 16, 128)  0           conv2d_180[0][0]                 \n",
            "                                                                 batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_179 (ReLU)                (None, 16, 16, 128)  0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_179[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 16, 16, 64)   256         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_180 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_180[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 16, 16, 64)   256         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_181 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_181[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 16, 16, 128)  512         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 128)  0           batch_normalization_182[0][0]    \n",
            "                                                                 re_lu_179[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_182 (ReLU)                (None, 16, 16, 128)  0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_182[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 16, 16, 64)   256         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_183 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_183[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 16, 16, 64)   256         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_184 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_184[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 16, 16, 128)  512         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 128)  0           batch_normalization_185[0][0]    \n",
            "                                                                 re_lu_182[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_185 (ReLU)                (None, 16, 16, 128)  0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_185[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 16, 16, 64)   256         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_186 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_186[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 16, 16, 64)   256         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_187 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_187[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 16, 16, 128)  512         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 16, 16, 128)  0           batch_normalization_188[0][0]    \n",
            "                                                                 re_lu_185[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_188 (ReLU)                (None, 16, 16, 128)  0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 128)  16512       re_lu_188[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 16, 16, 128)  512         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_189 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_189[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 128)    512         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_190 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_190[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_188[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 256)    1024        conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 8, 8, 256)    0           conv2d_193[0][0]                 \n",
            "                                                                 batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_191 (ReLU)                (None, 8, 8, 256)    0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_191[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 128)    512         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_192 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_192[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 128)    512         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_193 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_193[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 256)    1024        conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n",
            "                                                                 re_lu_191[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_194 (ReLU)                (None, 8, 8, 256)    0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 128)    512         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_195 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_195[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 128)    512         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_196 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_196[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 256)    1024        conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 8, 8, 256)    0           batch_normalization_197[0][0]    \n",
            "                                                                 re_lu_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_197 (ReLU)                (None, 8, 8, 256)    0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_197[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 128)    512         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_198 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_198[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 128)    512         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_199 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_199[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 8, 8, 256)    1024        conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 8, 8, 256)    0           batch_normalization_200[0][0]    \n",
            "                                                                 re_lu_197[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_200 (ReLU)                (None, 8, 8, 256)    0           add_65[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,121,344\n",
            "Trainable params: 1,114,400\n",
            "Non-trainable params: 6,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p97R8dh6ruHl"
      },
      "source": [
        "## The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__VH51b3b2dG",
        "outputId": "32820f60-ce9d-4e92-ea41-6a009c926066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load the training set of CIFAR10\n",
        "(X_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "X_train = X_train/255.\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-8CNXBusWXA"
      },
      "source": [
        "! wget -q https://github.com/ariG23498/G-SimCLR/releases/download/v2.0/CIFAR10.zip\n",
        "! unzip -q CIFAR10.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bkrUYGVueDY"
      },
      "source": [
        "auto_model = tf.keras.models.load_model('autoencoder_cifar10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCYL_JwOuuqL",
        "outputId": "6f0b804f-ab43-4805-8936-abf259717028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "auto_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "retrieval (MaxPooling2D)     (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "auto_output (Conv2D)         (None, 32, 32, 3)         867       \n",
            "=================================================================\n",
            "Total params: 335,747\n",
            "Trainable params: 334,851\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB-uV7ZGuxHu",
        "outputId": "047f34a5-8951-482f-f7e0-7801f300d8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "layer_name = 'retrieval'\n",
        "slice_model = tf.keras.Model(\n",
        "    inputs=auto_model.input,\n",
        "    outputs=auto_model.get_layer(layer_name).output\n",
        "    )\n",
        "slice_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "retrieval (MaxPooling2D)     (None, 4, 4, 128)         0         \n",
            "=================================================================\n",
            "Total params: 94,144\n",
            "Trainable params: 93,696\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVR5GO8vu6Aq"
      },
      "source": [
        "latent_train = slice_model.predict(X_train)\n",
        "embedding_train = tf.keras.layers.GlobalAveragePooling2D()(latent_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9DAwWkKvLPD"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMVX6At6rwR7",
        "outputId": "16d2b957-237e-4fef-8739-64a03f4c412a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "classifier = KMeans(n_clusters=BATCH_SIZE, random_state=0).fit(embedding_train)\n",
        "# labels of the clusters\n",
        "labels = classifier.labels_\n",
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5J421j1rxhY"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hJ0mMfr0ZX",
        "outputId": "b2ee8211-4845-4dd1-cfab-93c204d92527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Building the DataFrame\n",
        "df = pd.DataFrame()\n",
        "df['cluster_labels'] = labels\n",
        "df['imag_ind'] = np.arange(0,len(df))\n",
        "df = df[['imag_ind','cluster_labels']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   imag_ind  cluster_labels\n",
              "0         0              39\n",
              "1         1              57\n",
              "2         2              61\n",
              "3         3               1\n",
              "4         4              41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO0oWeo5r5Yz",
        "outputId": "ed14062c-81d3-495e-c384-1ecfeaa1579c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# The rank according to the cluster_labels\n",
        "df[\"rank\"] = df.groupby(\"cluster_labels\")[\"imag_ind\"].rank(\"dense\", ascending=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   imag_ind  cluster_labels  rank\n",
              "0         0              39   1.0\n",
              "1         1              57   1.0\n",
              "2         2              61   1.0\n",
              "3         3               1   1.0\n",
              "4         4              41   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpZrxp0Tr5PO",
        "outputId": "befcee47-248b-4a40-f75d-1f9b741a92e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Sorting the labels by cluster_labels and rank\n",
        "df_data = df.sort_values(by = ['cluster_labels','rank'])\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>282</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     imag_ind  cluster_labels  rank\n",
              "7           7               0   1.0\n",
              "52         52               0   2.0\n",
              "113       113               0   3.0\n",
              "143       143               0   4.0\n",
              "282       282               0   5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVw8w0gyr5Ev",
        "outputId": "24cf4f2d-fd2e-4c92-e724-9910de56772d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Sort with respect to rank only\n",
        "df_data2 = df_data.sort_values(by = ['rank'])\n",
        "df_data2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imag_ind</th>\n",
              "      <th>cluster_labels</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>47</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>49</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    imag_ind  cluster_labels  rank\n",
              "7          7               0   1.0\n",
              "82        82              47   1.0\n",
              "57        57              48   1.0\n",
              "92        92              49   1.0\n",
              "20        20              13   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEwNR7msBvl",
        "outputId": "16743c7f-6d86-4625-d911-33a8477c1697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "arr_ind = df_data2['imag_ind'].values\n",
        "X_train = X_train[arr_ind]\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYHjsLamsI4B"
      },
      "source": [
        "## Continuation with SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4csOqgEZb8MP"
      },
      "source": [
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):\n",
        "        \n",
        "        # Random flips\n",
        "        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "        \n",
        "        # randomly apply transformation (color distortions and blur) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=0.5)\n",
        "        sample = self._random_apply(self._color_drop, sample, p=0.5)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x, s=0.2):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _color_drop(self, x):\n",
        "        image = tf.image.rgb_to_grayscale(x)\n",
        "        image = tf.tile(x, [1, 1, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfNCi9M2ZuVz"
      },
      "source": [
        "data_augmentation = Sequential([Lambda(CustomAugment())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_IV81xc_sW"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "# # Create TensorFlow dataset\n",
        "# def normalize(image):\n",
        "#     return tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train))\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    # .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    # .cache()\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzrjGfJ0ZuV7",
        "outputId": "f282b542-17a3-462a-eba3-4f9e6de45677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-01 14:31:21--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘helpers.py’\n",
            "\n",
            "\rhelpers.py            0%[                    ]       0  --.-KB/s               \rhelpers.py          100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-01 14:31:22 (35.0 MB/s) - ‘helpers.py’ saved [891/891]\n",
            "\n",
            "--2020-10-01 14:31:22--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘losses.py’\n",
            "\n",
            "losses.py           100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-01 14:31:22 (48.7 MB/s) - ‘losses.py’ saved [891/891]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvEQyVmHP-vP"
      },
      "source": [
        "Don't forget to comment the augmentation import in the `helpers.py` script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LEpyZJQDjL"
      },
      "source": [
        "from losses import _dot_simililarity_dim1 as sim_func_dim1, _dot_simililarity_dim2 as sim_func_dim2\n",
        "import helpers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACHBh0MfQInT"
      },
      "source": [
        "# Mask to remove positive examples from the batch of negative samples\n",
        "negative_mask = helpers.get_negative_mask(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0dG8RWfZuWC"
      },
      "source": [
        "# Architecture utils\n",
        "def get_resnet_simclr_deeper(hidden_1, hidden_2, hidden_3):\n",
        "    inputs = Input((32, 32, 3))\n",
        "    h = resnet_headless_model(inputs, training=True)\n",
        "    h = GlobalAveragePooling2D()(h)\n",
        "    \n",
        "    projection_1 = Dense(hidden_1)(h)\n",
        "    projection_1 = Activation(\"relu\")(projection_1)\n",
        "    projection_2 = Dense(hidden_2)(projection_1)\n",
        "    projection_2 = Activation(\"relu\")(projection_2)\n",
        "    projection_3 = Dense(hidden_3)(projection_2)\n",
        "\n",
        "    resnet_simclr = Model(inputs, projection_3)\n",
        "\n",
        "    return resnet_simclr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwbPUDNCuU8F"
      },
      "source": [
        "@tf.function\n",
        "def train_step(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        zis = model(xis)\n",
        "        zjs = model(xjs)\n",
        "\n",
        "        # normalize projection feature vectors\n",
        "        zis = tf.math.l2_normalize(zis, axis=1)\n",
        "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
        "\n",
        "        l_pos = sim_func_dim1(zis, zjs)\n",
        "        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n",
        "        l_pos /= temperature\n",
        "\n",
        "        negatives = tf.concat([zjs, zis], axis=0)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for positives in [zis, zjs]:\n",
        "            l_neg = sim_func_dim2(positives, negatives)\n",
        "\n",
        "            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n",
        "\n",
        "            l_neg = tf.boolean_mask(l_neg, negative_mask)\n",
        "            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1))\n",
        "            l_neg /= temperature\n",
        "\n",
        "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
        "            loss += criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "        loss = loss / (2 * BATCH_SIZE)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uym2xu_tQ0wr"
      },
      "source": [
        "def train_simclr(model, dataset, optimizer, criterion,\n",
        "                 temperature=0.1, epochs=100):\n",
        "    step_wise_loss = []\n",
        "    epoch_wise_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for image_batch in dataset:\n",
        "            a = data_augmentation(image_batch)\n",
        "            b = data_augmentation(image_batch)\n",
        "\n",
        "            loss = train_step(a, b, model, optimizer, criterion, temperature)\n",
        "            step_wise_loss.append(loss)\n",
        "\n",
        "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "        wandb.log({\"nt_xentloss\": np.mean(step_wise_loss)})\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
        "\n",
        "    return epoch_wise_loss, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4EtTFFAZuWK",
        "outputId": "9513600c-e66b-46c6-ffa7-0de0597bb733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "    reduction=tf.keras.losses.Reduction.SUM)\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(entity=\"g-simclr\", project=\"g-simclr\", id=\"cifar10-gsimclr\")\n",
        "\n",
        "# Train SimCLR with SGD with CosineDecay restarts\n",
        "first_decay_steps = 1000\n",
        "lr_decayed_fn = (\n",
        "  tf.keras.experimental.CosineDecayRestarts(\n",
        "      initial_learning_rate=0.1,\n",
        "      first_decay_steps=first_decay_steps))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "resnet_simclr_2 = get_resnet_simclr_deeper(256, 128, 50)\n",
        "\n",
        "epoch_wise_loss, resnet_simclr  = train_simclr(resnet_simclr_2, train_ds, \n",
        "    optimizer, criterion,\n",
        "    temperature=0.1, epochs=15)\n",
        "\n",
        "with plt.xkcd():\n",
        "    plt.plot(epoch_wise_loss)\n",
        "    plt.title(\"tau = 0.1, h1 = 256, h2 = 128, h3 = 50\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.4<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">cifar10-gsimclr</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/g-simclr/g-simclr\" target=\"_blank\">https://wandb.ai/g-simclr/g-simclr</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/g-simclr/g-simclr/runs/cifar10-gsimclr\" target=\"_blank\">https://wandb.ai/g-simclr/g-simclr/runs/cifar10-gsimclr</a><br/>\n",
              "                Run data is saved locally in <code>wandb/run-20201001_143504-cifar10-gsimclr</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lambda is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [02:54<40:36, 174.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: 0.258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 11/15 [30:36<11:06, 166.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 11 loss: 0.057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [41:41<00:00, 166.75s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}